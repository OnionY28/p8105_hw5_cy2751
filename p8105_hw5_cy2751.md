p8105_hw5_cy2752
================
Congyu Yang
2024-11-09

## Problem 1

## Problem 2

``` r
randomset <-  function(n = 30,mu,sigma = 5) {
  
  x = rnorm(n,mu,sigma)
  
  x %>%t.test()%>% 
    broom::tidy() %>% select(estimate,p.value) %>% 
    mutate(power = ifelse(p.value < 0.05,T,F),
           mu = mu)
}

output = vector("list", 5000)
output_set <- vector("list",6)

for (j in 1:6) {
  for (i in 1:5000) {
  
  output[[i]] = randomset(mu = j)
  
  }
  output_set[[j]] <- bind_rows(output)
}
```

## Make a plot

``` r
output_set %>%
  bind_rows() %>% 
  group_by(mu) %>% 
  summarise(prop_power = mean(power)) %>% 
  ggplot(aes(x = mu, y =prop_power)) + 
  geom_point()+geom_line()
```

<img src="p8105_hw5_cy2751_files/figure-gfm/unnamed-chunk-2-1.png" width="90%" />

As we can see, as the true value of $\mu$ going larger, the power is
approaching towards 1, since we are always doing the test comparing if
the mean is equal to 0, so as the true mean moves away from 0, the power
of the test is getting higher.

``` r
mu_compare_all <- output_set %>%
  bind_rows() %>% 
  group_by(mu) %>% 
  summarise(avg_estimate = mean(estimate)) %>% 
  ggplot(aes(x = mu, y =avg_estimate)) + 
  geom_point()+geom_line()+
  xlim(0,7)+ ylim(0,7)

mu_compare_only_reject <-output_set %>%
  bind_rows() %>% 
  filter(power == T) %>% 
  group_by(mu) %>% 
  summarise(avg_estimate = mean(estimate)) %>% 
  ggplot(aes(x = mu, y =avg_estimate)) + 
  geom_point()+geom_line()+
  xlim(0,7)+ ylim(0,7)

mu_compare_all + mu_compare_only_reject
```

<img src="p8105_hw5_cy2751_files/figure-gfm/unnamed-chunk-3-1.png" width="90%" />

The sample average of $\hat{\mu}$ across tests for which the null is
rejected is not equal to(larger than) the true value of $\mu$ when the
$\mu$ is smaller, but as $\mu$ getting far away from 0, they are getting
closer and equal to each other.  

This is because our test is about whether $\mu$ = 0, so when we do this
test on small $\mu$, samples $\hat{\mu}$ across tests for which the null
is rejected are far away from 0, so it will also be away from the true
value of $\mu$.  

While for larger $\mu$, almost all samples have their null hypothesis
rejected, so it is actually compare the average of all estimate of
$\hat{\mu}$ and the true value of $\mu$, accordingly, sample average of
$\hat{\mu}$ across tests for which the null is rejected is equal to the
true value of $\mu$ when $\mu$ gets far away from 0.

# Problem 3

There is one row that mistakenly write city `Tulsa` belongs to state
`AL`, which should belongs to `OK`, so we remove this row for
inprecision reason.

``` r
homicide <- read_csv("data/homicide-data.csv") %>% 
  mutate(city_state = str_c(city,state,sep = ", ")) %>% 
  filter((city_state != "Tulsa, AL"))
```

    ## Rows: 52179 Columns: 12
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (9): uid, victim_last, victim_first, victim_race, victim_age, victim_sex...
    ## dbl (3): reported_date, lat, lon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
total_homicide <- homicide %>% 
  group_by(city_state) %>% 
  summarize(total_cases = n()) 

unsolved_homiside <- homicide %>% 
  filter(disposition == "Closed without arrest" | disposition == "Open/No arrest") %>% 
  group_by(city_state) %>% 
  summarize(unsolved_cases = n()) 

(cases_table <- left_join(total_homicide,unsolved_homiside, by = "city_state"))
```

    ## # A tibble: 50 × 3
    ##    city_state      total_cases unsolved_cases
    ##    <chr>                 <int>          <int>
    ##  1 Albuquerque, NM         378            146
    ##  2 Atlanta, GA             973            373
    ##  3 Baltimore, MD          2827           1825
    ##  4 Baton Rouge, LA         424            196
    ##  5 Birmingham, AL          800            347
    ##  6 Boston, MA              614            310
    ##  7 Buffalo, NY             521            319
    ##  8 Charlotte, NC           687            206
    ##  9 Chicago, IL            5535           4073
    ## 10 Cincinnati, OH          694            309
    ## # ℹ 40 more rows

This dataset about homicides in 50 large U.S. cities has 52178 rows and
14 columns. It has more than 52000 criminal homicides over the past
decade. And it includes the date of the cases，basic information about
the suspect，location of the cases and whether the arrest has been made.

``` r
BalMD <- cases_table %>% 
  filter(city_state == "Baltimore, MD")

(prop_test_BalMD <-
  prop.test(x = BalMD %>% pull(unsolved_cases), n = BalMD %>% pull(total_cases)) %>%
  broom::tidy() %>% 
  select(estimate,conf.low,conf.high) %>% 
  mutate(city = BalMD %>% select(city_state)) %>% 
  unnest())
```

    ## # A tibble: 1 × 4
    ##   estimate conf.low conf.high city_state   
    ##      <dbl>    <dbl>     <dbl> <chr>        
    ## 1    0.646    0.628     0.663 Baltimore, MD

``` r
est_and_CI <- function(state){
  
  City <- cases_table %>% filter(city_state == state)
  
  prop.test(x = City %>% pull(unsolved_cases), n = City %>% pull(total_cases)) %>%
  broom::tidy() %>% 
  select(estimate,conf.low,conf.high) %>% 
    mutate(city = City %>% select(city_state)) %>% 
  unnest()
  
}


(prop_test_all <- map_dfr(cases_table %>% pull(city_state), \(x) est_and_CI(x)))
```

    ## # A tibble: 50 × 4
    ##    estimate conf.low conf.high city_state     
    ##       <dbl>    <dbl>     <dbl> <chr>          
    ##  1    0.386    0.337     0.438 Albuquerque, NM
    ##  2    0.383    0.353     0.415 Atlanta, GA    
    ##  3    0.646    0.628     0.663 Baltimore, MD  
    ##  4    0.462    0.414     0.511 Baton Rouge, LA
    ##  5    0.434    0.399     0.469 Birmingham, AL 
    ##  6    0.505    0.465     0.545 Boston, MA     
    ##  7    0.612    0.569     0.654 Buffalo, NY    
    ##  8    0.300    0.266     0.336 Charlotte, NC  
    ##  9    0.736    0.724     0.747 Chicago, IL    
    ## 10    0.445    0.408     0.483 Cincinnati, OH 
    ## # ℹ 40 more rows

``` r
prop_test_all %>% 
  arrange(desc(estimate)) %>% 
  mutate(city_state = reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
    geom_point()+
  theme(axis.text.x = element_text(size = 5,angle = 30))
```

<img src="p8105_hw5_cy2751_files/figure-gfm/unnamed-chunk-6-1.png" width="90%" />
